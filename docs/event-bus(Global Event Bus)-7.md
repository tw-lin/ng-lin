# Global Event Bus - Level 7: ç”Ÿç”¢ç’°å¢ƒæœ€ä½³åŒ–

> **æ¼”é€²éšæ®µ**: ä¼æ¥­ç´šç”Ÿç”¢éƒ¨ç½²  
> **ç‹€æ…‹**: ğŸ“ è¦åŠƒä¸­  
> **æ—¥æœŸ**: 2025-12-25

---

## æ¦‚è¿°

æœ¬æ–‡æª”æ¶µè“‹ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²çš„æœ€ä½³å¯¦è¸ï¼ŒåŒ…å«å¤šå€åŸŸéƒ¨ç½²ã€ç½é›£æ¢å¾©ã€æ•ˆèƒ½èª¿æ ¡ã€æˆæœ¬å„ªåŒ–å’Œåˆè¦æ€§è¦æ±‚ã€‚

---

## å¤šå€åŸŸéƒ¨ç½²

### 1. è·¨åœ°åŸŸè¤‡è£½æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Global Load Balancer                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                   â”‚
        â†“                                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Asia Region     â”‚              â”‚  US Region       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Event Bus  â”‚â†â”€â”¼â”€â”€replicationâ”€â”¼â”€â†’â”‚ Event Bus  â”‚  â”‚
â”‚  â”‚  (Kafka)   â”‚  â”‚              â”‚  â”‚  (Kafka)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Event Store â”‚  â”‚              â”‚  â”‚Event Store â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Kafka MirrorMaker é…ç½®

```yaml
# mirror-maker.yml
clusters:
  asia:
    bootstrap.servers: kafka-asia-1:9092,kafka-asia-2:9092,kafka-asia-3:9092
  us:
    bootstrap.servers: kafka-us-1:9092,kafka-us-2:9092,kafka-us-3:9092

mirrors:
  - source: asia
    target: us
    topics:
      - task.*
      - blueprint.*
      - notification.*
    replication.factor: 3
    
  - source: us
    target: asia
    topics:
      - task.*
      - blueprint.*
      - notification.*
    replication.factor: 3
```

### 3. å€åŸŸæ„ŸçŸ¥è·¯ç”±

```typescript
@Injectable({ providedIn: 'root' })
export class RegionalEventBus implements IEventBus {
  private readonly regionService = inject(RegionService);
  private readonly asiaBus = inject(KafkaEventBusAsia);
  private readonly usBus = inject(KafkaEventBusUS);
  
  async publish(event: DomainEvent): Promise<void> {
    const region = await this.regionService.getCurrentRegion();
    
    const bus = region === 'asia' ? this.asiaBus : this.usBus;
    return bus.publish(event);
  }
  
  observe<T extends DomainEvent>(eventType: string): Observable<T> {
    // å¾å…©å€‹å€åŸŸåˆä½µäº‹ä»¶æµ
    return merge(
      this.asiaBus.observe<T>(eventType),
      this.usBus.observe<T>(eventType)
    ).pipe(
      // å»é‡ï¼ˆé¿å…é‡è¤‡è™•ç†ç›¸åŒäº‹ä»¶ï¼‰
      distinctUntilChanged((a, b) => a.eventId === b.eventId)
    );
  }
}
```

---

## ç½é›£æ¢å¾© (DR)

### 1. å‚™ä»½ç­–ç•¥

#### äº‹ä»¶å‚™ä»½åˆ° S3

```typescript
@Injectable()
export class EventBackupService {
  private readonly s3 = new S3Client({ region: 'us-west-2' });
  
  async backupEvents(date: Date): Promise<void> {
    const events = await this.eventStore.query({
      fromTimestamp: startOfDay(date),
      toTimestamp: endOfDay(date)
    });
    
    const backup = {
      date: date.toISOString(),
      eventCount: events.length,
      events: events
    };
    
    await this.s3.send(new PutObjectCommand({
      Bucket: 'gighub-event-backups',
      Key: `events/${date.toISOString().split('T')[0]}.json.gz`,
      Body: gzip(JSON.stringify(backup)),
      ServerSideEncryption: 'AES256'
    }));
  }
  
  async restoreEvents(date: Date): Promise<void> {
    const response = await this.s3.send(new GetObjectCommand({
      Bucket: 'gighub-event-backups',
      Key: `events/${date.toISOString().split('T')[0]}.json.gz`
    }));
    
    const backup = JSON.parse(ungzip(await response.Body.transformToByteArray()));
    
    for (const event of backup.events) {
      await this.eventStore.append(event);
    }
  }
}
```

### 2. å¿«ç…§å‚™ä»½

```typescript
export class SnapshotBackupService {
  async createBackup(): Promise<void> {
    // 1. æš«åœå¯«å…¥
    await this.eventBus.pause();
    
    // 2. å‰µå»ºæ‰€æœ‰ Aggregate å¿«ç…§
    const aggregates = await this.getActiveAggregates();
    
    for (const aggregate of aggregates) {
      const snapshot = await this.createSnapshot(aggregate);
      await this.s3.uploadSnapshot(snapshot);
    }
    
    // 3. æ¢å¾©å¯«å…¥
    await this.eventBus.resume();
  }
  
  async restoreFromBackup(backupId: string): Promise<void> {
    const snapshots = await this.s3.downloadSnapshots(backupId);
    
    for (const snapshot of snapshots) {
      await this.snapshotStore.save(snapshot);
    }
  }
}
```

### 3. ç½é›£æ¢å¾©è¨ˆç•«

```typescript
export class DisasterRecoveryPlan {
  async executeFailover(): Promise<void> {
    console.log('[DR] Initiating failover to secondary region...');
    
    // 1. åœæ­¢ä¸»å€åŸŸæµé‡
    await this.loadBalancer.removeRegion('primary');
    
    // 2. æå‡æ¬¡è¦å€åŸŸç‚ºä¸»
    await this.promoteSecondaryToPrimary();
    
    // 3. é‡æ–°è·¯ç”±æµé‡
    await this.loadBalancer.addRegion('secondary-promoted', { priority: 1 });
    
    // 4. é©—è­‰æœå‹™å¥åº·
    await this.healthCheck.verify();
    
    console.log('[DR] Failover completed successfully');
  }
  
  async executeFailback(): Promise<void> {
    // ç½é›£æ¢å¾©å¾Œæ¢å¾©æ­£å¸¸
    await this.restorePrimaryRegion();
    await this.loadBalancer.addRegion('primary', { priority: 1 });
    await this.loadBalancer.removeRegion('secondary-promoted');
  }
}
```

---

## æ•ˆèƒ½èª¿æ ¡

### 1. Kafka èª¿å„ª

```properties
# server.properties

# å¢åŠ åˆ†å€æ•¸ä»¥æå‡ä¸¦è¡Œåº¦
num.partitions=12

# èª¿æ•´è¤‡è£½å› å­ï¼ˆå¹³è¡¡å¯ç”¨æ€§èˆ‡æ•ˆèƒ½ï¼‰
default.replication.factor=3
min.insync.replicas=2

# å¢åŠ ç·©è¡å€å¤§å°
socket.send.buffer.bytes=1048576
socket.receive.buffer.bytes=1048576

# æ‰¹æ¬¡è™•ç†å„ªåŒ–
batch.size=16384
linger.ms=10

# å£“ç¸®
compression.type=snappy

# æ—¥èªŒä¿ç•™
log.retention.hours=168
log.segment.bytes=1073741824

# è¨˜æ†¶é«”åˆ†é…
heap.size=8G
```

### 2. ç”Ÿç”¢è€…å„ªåŒ–

```typescript
export class OptimizedKafkaProducer {
  private producer: Producer;
  
  constructor() {
    this.producer = new Kafka({
      clientId: 'gighub',
      brokers: ['kafka1:9092', 'kafka2:9092', 'kafka3:9092']
    }).producer({
      // æ‰¹æ¬¡è™•ç†
      batch: {
        size: 16384,
        lingerMs: 10
      },
      // å£“ç¸®
      compression: CompressionTypes.Snappy,
      // é‡è©¦
      retry: {
        retries: 5,
        initialRetryTime: 100,
        maxRetryTime: 30000
      },
      // å†ªç­‰æ€§ï¼ˆé¿å…é‡è¤‡ï¼‰
      idempotent: true,
      // äº¤æ˜“æ”¯æ´
      transactionalId: 'gighub-tx'
    });
  }
}
```

### 3. æ¶ˆè²»è€…å„ªåŒ–

```typescript
export class OptimizedKafkaConsumer {
  private consumer: Consumer;
  
  constructor() {
    this.consumer = new Kafka({
      clientId: 'gighub',
      brokers: ['kafka1:9092', 'kafka2:9092', 'kafka3:9092']
    }).consumer({
      groupId: 'task-consumers',
      // è‡ªå‹•æäº¤
      autoCommit: false,
      // æ‰¹æ¬¡è®€å–
      maxBytesPerPartition: 1048576,
      // æœƒè©±è¶…æ™‚
      sessionTimeout: 30000,
      heartbeatInterval: 3000
    });
    
    this.consumer.run({
      partitionsConsumedConcurrently: 3, // ä¸¦è¡Œè™•ç†
      eachBatch: async ({ batch, resolveOffset, commitOffsetsIfNecessary }) => {
        for (const message of batch.messages) {
          await this.processMessage(message);
          resolveOffset(message.offset);
        }
        
        // æ‰¹æ¬¡æäº¤
        await commitOffsetsIfNecessary();
      }
    });
  }
}
```

### 4. å¿«å–ç­–ç•¥

```typescript
@Injectable()
export class CachedEventStore {
  private cache = new LRUCache<string, DomainEvent[]>({
    max: 1000,
    maxAge: 300000 // 5 åˆ†é˜
  });
  
  async query(options: QueryOptions): Promise<DomainEvent[]> {
    const cacheKey = this.getCacheKey(options);
    
    // æª¢æŸ¥å¿«å–
    const cached = this.cache.get(cacheKey);
    if (cached) {
      return cached;
    }
    
    // å¾è³‡æ–™åº«æŸ¥è©¢
    const events = await this.innerStore.query(options);
    
    // å­˜å…¥å¿«å–
    this.cache.set(cacheKey, events);
    
    return events;
  }
}
```

---

## æˆæœ¬å„ªåŒ–

### 1. äº‹ä»¶æ­¸æª”

```typescript
export class EventArchivalService {
  async archiveOldEvents(olderThan: Date): Promise<void> {
    // 1. æŸ¥è©¢èˆŠäº‹ä»¶
    const oldEvents = await this.eventStore.query({
      toTimestamp: olderThan
    });
    
    // 2. å£“ç¸®ä¸¦ä¸Šå‚³åˆ° S3 Glacier
    const archived = {
      archivedAt: new Date(),
      eventCount: oldEvents.length,
      events: oldEvents
    };
    
    await this.s3.send(new PutObjectCommand({
      Bucket: 'gighub-event-archive',
      Key: `archive/${olderThan.getFullYear()}/${olderThan.getMonth()}.json.gz`,
      Body: gzip(JSON.stringify(archived)),
      StorageClass: 'GLACIER'
    }));
    
    // 3. å¾ä¸»å„²å­˜åˆªé™¤
    for (const event of oldEvents) {
      await this.eventStore.delete(event.eventId);
    }
  }
}
```

### 2. è³‡æºä½¿ç”¨ç›£æ§

```typescript
export class CostMonitoringService {
  async generateCostReport(): Promise<CostReport> {
    return {
      kafka: {
        instanceCost: await this.getKafkaInstanceCost(),
        storageCost: await this.getKafkaStorageCost(),
        dataTrasferCost: await this.getDataTransferCost()
      },
      s3: {
        storageCost: await this.getS3StorageCost(),
        requestCost: await this.getS3RequestCost()
      },
      total: 0 // è¨ˆç®—ç¸½æˆæœ¬
    };
  }
  
  async optimizeCosts(): Promise<Optimization[]> {
    const optimizations: Optimization[] = [];
    
    // æª¢æŸ¥æœªä½¿ç”¨çš„ topics
    const unusedTopics = await this.findUnusedTopics();
    if (unusedTopics.length > 0) {
      optimizations.push({
        type: 'delete-unused-topics',
        savings: this.estimateSavings(unusedTopics),
        topics: unusedTopics
      });
    }
    
    // æª¢æŸ¥å¯æ­¸æª”çš„äº‹ä»¶
    const archivableEvents = await this.findArchivableEvents();
    if (archivableEvents > 0) {
      optimizations.push({
        type: 'archive-old-events',
        savings: this.estimateArchiveSavings(archivableEvents)
      });
    }
    
    return optimizations;
  }
}
```

---

## åˆè¦æ€§

### 1. GDPR è³‡æ–™åˆªé™¤

```typescript
export class GDPRComplianceService {
  async deleteUserData(userId: string): Promise<void> {
    // 1. æŸ¥è©¢ç”¨æˆ¶ç›¸é—œäº‹ä»¶
    const userEvents = await this.eventStore.query({
      userContext: { userId }
    });
    
    // 2. åŒ¿ååŒ–äº‹ä»¶ï¼ˆä¿ç•™æ¥­å‹™é‚è¼¯ï¼Œç§»é™¤å€‹äººè³‡æ–™ï¼‰
    for (const event of userEvents) {
      const anonymized = this.anonymizeEvent(event);
      await this.eventStore.replace(event.eventId, anonymized);
    }
    
    // 3. è¨˜éŒ„åˆªé™¤è«‹æ±‚
    await this.auditLog.record({
      action: 'gdpr-data-deletion',
      userId,
      timestamp: new Date(),
      eventCount: userEvents.length
    });
  }
  
  private anonymizeEvent(event: DomainEvent): DomainEvent {
    return {
      ...event,
      metadata: {
        ...event.metadata,
        userContext: {
          userId: 'ANONYMIZED',
          roles: event.metadata.userContext?.roles || []
        }
      },
      payload: this.anonymizePayload(event.payload)
    };
  }
}
```

### 2. SOC2 ç¨½æ ¸è¿½è¹¤

```typescript
export class SOC2AuditService {
  async generateAuditReport(from: Date, to: Date): Promise<AuditReport> {
    const events = await this.eventStore.query({
      fromTimestamp: from,
      toTimestamp: to
    });
    
    return {
      period: { from, to },
      totalEvents: events.length,
      eventsByType: this.groupByType(events),
      securityEvents: events.filter(e => e.eventType.startsWith('security.')),
      accessChanges: events.filter(e => e.eventType.includes('.permission.')),
      dataChanges: events.filter(e => e.eventType.includes('.updated')),
      integrityCheck: await this.verifyEventIntegrity(events)
    };
  }
  
  async verifyEventIntegrity(events: DomainEvent[]): Promise<boolean> {
    // é©—è­‰äº‹ä»¶éˆå®Œæ•´æ€§
    for (let i = 1; i < events.length; i++) {
      const prev = events[i - 1];
      const curr = events[i];
      
      // æª¢æŸ¥æ™‚é–“é †åº
      if (curr.timestamp < prev.timestamp) {
        return false;
      }
      
      // æª¢æŸ¥ causation éˆ
      if (curr.metadata.causationId !== prev.eventId) {
        // å…è¨±ä¸åŒèšåˆçš„äº‹ä»¶
        if (curr.aggregateId === prev.aggregateId) {
          return false;
        }
      }
    }
    
    return true;
  }
}
```

### 3. è³‡æ–™åŠ å¯†

```typescript
export class EncryptedEventStore implements IEventStore {
  private readonly kms = new KMSClient({ region: 'us-west-2' });
  private readonly keyId = 'alias/event-encryption-key';
  
  async append(event: DomainEvent): Promise<void> {
    // åŠ å¯†æ•æ„Ÿæ¬„ä½
    const encrypted = await this.encryptSensitiveData(event);
    
    await this.innerStore.append(encrypted);
  }
  
  async query(options: QueryOptions): Promise<DomainEvent[]> {
    const events = await this.innerStore.query(options);
    
    // è§£å¯†
    return Promise.all(
      events.map(event => this.decryptSensitiveData(event))
    );
  }
  
  private async encryptSensitiveData(event: DomainEvent): Promise<DomainEvent> {
    const sensitiveFields = this.extractSensitiveFields(event.payload);
    
    const encrypted = await this.kms.send(new EncryptCommand({
      KeyId: this.keyId,
      Plaintext: Buffer.from(JSON.stringify(sensitiveFields))
    }));
    
    return {
      ...event,
      payload: {
        ...event.payload,
        _encrypted: encrypted.CiphertextBlob.toString('base64')
      }
    };
  }
}
```

---

## ç›£æ§èˆ‡å‘Šè­¦

### 1. å…¨é¢ç›£æ§

```typescript
export class EventBusMonitoring {
  // Prometheus metrics
  private publishLatency = new Histogram({
    name: 'event_publish_latency_ms',
    help: 'Event publish latency in milliseconds',
    labelNames: ['event_type', 'region']
  });
  
  private consumerLag = new Gauge({
    name: 'consumer_lag',
    help: 'Consumer lag in messages',
    labelNames: ['consumer_group', 'topic', 'partition']
  });
  
  private errorRate = new Counter({
    name: 'event_errors_total',
    help: 'Total number of event errors',
    labelNames: ['error_type', 'event_type']
  });
  
  async collectMetrics(): Promise<void> {
    // æ”¶é›†æ¶ˆè²»è€…å»¶é²
    const lag = await this.kafka.admin().fetchOffsets({
      groupId: 'task-consumers'
    });
    
    for (const topic of lag) {
      for (const partition of topic.partitions) {
        this.consumerLag.set(
          { consumer_group: 'task-consumers', topic: topic.topic, partition: partition.partition },
          partition.offset - partition.metadata
        );
      }
    }
  }
}
```

### 2. å‘Šè­¦è¦å‰‡

```yaml
# prometheus-alerts.yml
groups:
  - name: event-bus
    rules:
      - alert: HighConsumerLag
        expr: consumer_lag > 10000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Consumer lag is high"
          description: "Consumer {{ $labels.consumer_group }} has lag of {{ $value }}"
      
      - alert: HighErrorRate
        expr: rate(event_errors_total[5m]) > 10
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors/sec"
      
      - alert: EventBusDown
        expr: up{job="event-bus"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Event Bus is down"
```

---

## ä¸‹ä¸€æ­¥ï¼ˆLevel 8ï¼‰

Level 8 å°‡æ¶µè“‹ï¼š

1. **æ©Ÿå™¨å­¸ç¿’æ•´åˆ**: ç•°å¸¸æª¢æ¸¬
2. **è‡ªå‹•æ“´ç¸®å®¹**: åŸºæ–¼è² è¼‰çš„è‡ªå‹•èª¿æ•´
3. **æ··æ²Œå·¥ç¨‹**: ç³»çµ±éŸŒæ€§æ¸¬è©¦
4. **é›¶åœæ©Ÿå‡ç´š**: æ»¾å‹•æ›´æ–°ç­–ç•¥
5. **å…¨çƒåˆ†æ•£å¼**: å¤šé›²æ¶æ§‹

---

**æ–‡æª”ç‰ˆæœ¬**: 7.0  
**æœ€å¾Œæ›´æ–°**: 2025-12-25  
**ç¶­è­·è€…**: GigHub é–‹ç™¼åœ˜éšŠ
